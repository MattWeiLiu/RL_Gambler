{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a8469b-1fd0-4bbf-8025-b006cc53bef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tqdm.auto import tqdm\n",
    "from configuration import Config\n",
    "from Simulation.model import LuxuryDiceSimulationMdn as Model\n",
    "from Simulation.loss import MdnLoss\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d03da2f-dc5a-4dcf-aad8-234942570331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- APP CONFIG ----------------------------------\n",
      "data: \n",
      "  data_path: gs://bin_for_aiops/GambleMaster/LuxuryDice/luxury_dice.npz\n",
      "  time_length: 15\n",
      "  train_test_split: 0.8\n",
      "train: \n",
      "  batch_size: 64\n",
      "  epoch: 1000\n",
      "test: \n",
      "  batch_size: 128\n",
      "model: \n",
      "  loss: MDN\n",
      "  metrics: MDN\n",
      "  alpha: 3\n",
      "optimizer: \n",
      "  method: adam\n",
      "  learning_rate: 1e-4\n",
      "weights: \n",
      "  simulation: weights/best_luxury_dice_simulation_model.tf\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 08:51:15.842665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-13 08:51:15.854497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-13 08:51:15.854732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Configuration Loading\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "config = Config(os.path.join(os.getcwd(), \"Simulation/config.yaml\"))\n",
    "\n",
    "# Set GPU as available physical device\n",
    "if gpus := tf.config.experimental.list_physical_devices(device_type='GPU'):\n",
    "    tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a9ad59-9b41-4405-b7bb-e885d6fdcca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Data Preparation\n",
    "    # x = np.random.rand(32, 15, 3)\n",
    "    # x = tf.cast(x, tf.float32)\n",
    "    # time_encode = np.random.rand(32, 2)\n",
    "    # time_encode = tf.cast(time_encode, tf.float32)\n",
    "    # y = np.random.rand(32, 13)\n",
    "    # y = tf.cast(y, tf.float32)\n",
    "    f = BytesIO(file_io.read_file_to_string(config.data.data_path, binary_mode=True))\n",
    "    data = np.load(f)\n",
    "    x, time_encode, y = data[\"record\"], data[\"time_code\"], data[\"y\"]\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    time_encode = tf.cast(time_encode, tf.float32)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "\n",
    "    k = int(config.data.train_test_split * x.shape[0])\n",
    "    x_train, x_test = x[:k, :, :], x[k:, :, :]\n",
    "    time_encode_train, time_encode_test = time_encode[:k, :], time_encode[k:, :]\n",
    "    y_train, y_test = y[:k, :], y[k:, :]\n",
    "\n",
    "    training_data = tf.data.Dataset.from_tensor_slices((x_train, time_encode_train, y_train))\n",
    "    training_batch = training_data.batch(config.train.batch_size)\n",
    "    testing_data = tf.data.Dataset.from_tensor_slices((x_test, time_encode_test, y_test))\n",
    "    testing_batch = testing_data.batch(config.train.batch_size)\n",
    "\n",
    "    #\n",
    "    # Create model (BetSimulation)\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    model = Model()\n",
    "\n",
    "    if config.optimizer.method == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=float(config.optimizer.learning_rate))\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=float(config.optimizer.learning_rate))\n",
    "\n",
    "    #\n",
    "    # Loss\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    # kld = tf.keras.losses.KLDivergence()\n",
    "    mdn_loss = MdnLoss(reduce=False)\n",
    "\n",
    "    #\n",
    "    # Train Model\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_train_loss = float(\"inf\")\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    for e in range(config.train.epoch):\n",
    "        train_loss_cache = []\n",
    "        test_loss_cache = []\n",
    "        for x, time, y in tqdm(training_batch, desc=\"Training\"):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # y_hat = model(x, time, training=True)\n",
    "                # train_loss = tf.keras.losses.MSE(y[:,:1], y_hat[:,:1]) * float(config.model.alpha) + kld(y[:,1:], y_hat[:,1:])\n",
    "                y_mu, y_sigma = model(x, time, training=True)\n",
    "                # neg_log_pdf = mdn_loss(y_mu, y_sigma, y)\n",
    "                # train_loss = tf.math.reduce_mean(neg_log_pdf[:, :1]) + tf.math.reduce_mean(\n",
    "                #     neg_log_pdf[:, 1:])\n",
    "                train_loss = tf.math.reduce_mean(mdn_loss(y_mu[:, :1], y_sigma[:, :1], y[:, :1], \"Normal\")) + tf.math.reduce_mean(mdn_loss(y_mu[:, 1:], y_sigma[:, 1:], y[:, 1:], \"Beta\"))\n",
    "\n",
    "            gradients = tape.gradient(train_loss, model.trainable_variables)\n",
    "            # print(gradients)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            train_loss_cache.append(train_loss.numpy())\n",
    "            # break\n",
    "\n",
    "        for x, time, y in tqdm(testing_batch, desc=\"Testing\"):\n",
    "            # y_hat = model(x, time)\n",
    "            # test_loss = tf.keras.losses.MSE(y[:,:1], y_hat[:,:1]) * float(config.model.alpha) + kld(y[:,1:], y_hat[:,1:])\n",
    "            y_mu, y_sigma = model(x, time)\n",
    "            # neg_log_pdf = mdn_loss(y_mu, y_sigma, y)\n",
    "            # test_loss = tf.math.reduce_mean(neg_log_pdf[:, :1]) * float(config.model.alpha) + tf.math.reduce_mean(\n",
    "            #     neg_log_pdf[:, 1:])\n",
    "            test_loss = tf.math.reduce_mean(mdn_loss(y_mu[:, :1], y_sigma[:, :1], y[:, :1], \"Normal\")) + tf.math.reduce_mean(mdn_loss(y_mu[:, 1:], y_sigma[:, 1:], y[:, 1:], \"Beta\"))\n",
    "            test_loss_cache.append(test_loss.numpy())\n",
    "            # break\n",
    "\n",
    "        train_loss_epoch = np.mean(train_loss_cache)\n",
    "        test_loss_epoch = np.mean(test_loss_cache)\n",
    "        train_losses.append(train_loss_epoch)\n",
    "        test_losses.append(test_loss_epoch)\n",
    "        \n",
    "        print('Epoch: {}/{}\\ttrain_loss: {:.6f}\\ttest_loss: {:.6f}'.\n",
    "              format(e + 1, config.train.epoch, train_loss_epoch, test_loss_epoch))\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e6a2d-d330-4dee-a6ad-df393d31e3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
